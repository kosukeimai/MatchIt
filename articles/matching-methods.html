<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Matching Methods • MatchIt</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Matching Methods">
<meta property="og:description" content="MatchIt">
<meta property="og:image" content="/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    

    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">MatchIt</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">4.3.3</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../articles/MatchIt.html">Get started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/matching-methods.html">Matching Methods</a>
    </li>
    <li>
      <a href="../articles/assessing-balance.html">Assessing Balance</a>
    </li>
    <li>
      <a href="../articles/estimating-effects.html">Estimating Effects After Matching</a>
    </li>
    <li>
      <a href="../articles/sampling-weights.html">Matching with Sampling Weights</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/kosukeimai/MatchIt/" class="external-link">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="matching-methods_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Matching Methods</h1>
                        <h4 data-toc-skip class="author">Noah Greifer</h4>
            
            <h4 data-toc-skip class="date">2022-01-16</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/kosukeimai/MatchIt/blob/HEAD/vignettes/matching-methods.Rmd" class="external-link"><code>vignettes/matching-methods.Rmd</code></a></small>
      <div class="hidden name"><code>matching-methods.Rmd</code></div>

    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p><code>MatchIt</code> implements several matching methods with a variety of options. Though the help pages for the individual methods describes each method and how they can be used, this vignette provides a broad overview of the available matching methods and their associated options. The choice of matching method depends on the goals of the analysis (e.g., the estimand, whether low bias or high precision is important) and the unique qualities of each dataset to be analyzed, so there is no single optimal choice for any given analysis. A benefit of nonparametric preprocessing through matching is that a number of matching methods can be tried and their quality assessed without consulting the outcome, reducing the possibility of capitalizing on chance while allowing for the benefits of an exploratory analysis in the design phase <span class="citation">(Ho et al. <a href="#ref-ho2007" role="doc-biblioref">2007</a>)</span>.</p>
<p>This vignette describes each matching method available in <code>MatchIt</code> and the various options that are allowed with matching methods and the consequences of their use. For a brief introduction to the use of <code>MatchIt</code> functions, see <code><a href="../articles/MatchIt.html">vignette("MatchIt")</a></code>. For details on how to assess and report covariate balance, see <code><a href="../articles/assessing-balance.html">vignette("assessing-balance")</a></code>. For details on how to estimate treatment effects and standard errors after matching, see <code><a href="../articles/estimating-effects.html">vignette("estimating-effects")</a></code>.</p>
</div>
<div class="section level2">
<h2 id="matching">Matching<a class="anchor" aria-label="anchor" href="#matching"></a>
</h2>
<p>Matching as implemented in <code>MatchIt</code> is a form of <em>subset selection</em>, that is, the pruning and weighting of units to arrive at a (weighted) subset of the units from the original dataset. Ideally, and if done successfully, subset selection produces a new sample where the treatment is unassociated with the covariates so that a comparison of the outcomes treatment and control groups is not confounded by the measured and balanced covariates. Although statistical estimation methods like regression can also be used to remove confounding due to measured covariates, <span class="citation">Ho et al. (<a href="#ref-ho2007" role="doc-biblioref">2007</a>)</span> argue that fitting regression models in matched samples reduces the dependence of the validity of the estimated treatment effect on the correct specification of the model.</p>
<p>Matching is nonparametric in the sense that the estimated weights and pruning of the sample are not direct functions of estimated model parameters but rather depend on the organization of discrete units in the sample; this is in contrast to propensity score weighting (also known as inverse probability weighting), where the weights come more directly from the estimated propensity score model and therefore are more sensitive to its correct specification. These advantages, as well as the intuitive understanding of matching by the public compared to regression or weighting, make it a robust and effective way to estimate treatment effects.</p>
<p>It is important to note that this implementation of matching differs from the methods described by Abadie and Imbens <span class="citation">(<a href="#ref-abadie2006" role="doc-biblioref">2006</a>, <a href="#ref-abadie2016" role="doc-biblioref">2016</a>)</span> and implemented in the <code>Matching</code> R package and <code>teffects</code> routine in Stata. That form of matching is <em>matching imputation</em>, where the missing potential outcomes for each unit are imputed using the observed outcomes of paired units. This is a critical distinction because matching imputation is a specific estimation method with its own effect and standard error estimators, in contrast to subset selection, which is a preprocessing method that does not require specific estimators and is broadly compatible with other parametric and nonparametric analyses. The benefits of matching imputation are that its theoretical properties (i.e., the rate of convergence and asymptotic variance of the estimator) are well understood, it can be used in a straightforward way to estimate not just the average treatment effect in the treated (ATT) but also the average treatment effect in the population (ATE), and additional effective matching methods can be used in the imputation (e.g., kernel matching). The benefits of matching as nonparametric preprocessing are that it is far more flexible with respect to the types of effects that can be estimated because it does not involve any specific estimator, its empirical and finite-sample performance has been examined in depth and is generally well understood, and it aligns well with the design of experiments, which are more familiar to non-technical audiences.</p>
<p>In addition to subset selection, matching often (though not always) involves a form of <em>stratification</em>, the assignment of units to pairs or strata containing multiple units. The distinction between subset selection and stratification is described by <span class="citation">Zubizarreta, Paredes, and Rosenbaum (<a href="#ref-zubizarreta2014" role="doc-biblioref">2014</a>)</span>, who separate them into two separate steps. In <code>MatchIt</code>, with almost all matching methods, subset selection is performed by stratification; for example, treated units are paired with control units, and unpaired units are then dropped from the matched sample. With some methods, subclasses are used to assign matching or stratification weights to individual units, which increase or decrease each unit’s leverage in a subsequent analysis. There has been some debate about the importance of stratification after subset selection; while some authors have argued that, with some forms of matching, pair membership is incidental <span class="citation">(Stuart <a href="#ref-stuart2008" role="doc-biblioref">2008</a>; Schafer and Kang <a href="#ref-schafer2008" role="doc-biblioref">2008</a>)</span>, others have argued that correctly incorporating pair membership into effect estimation can improve the quality of inferences <span class="citation">(Austin and Small <a href="#ref-austin2014a" role="doc-biblioref">2014</a>; Wan <a href="#ref-wan2019" role="doc-biblioref">2019</a>)</span>. For methods that allow it, <code>MatchIt</code> includes stratum membership as an additional output of each matching specification. How these strata can be used is detailed in <code>vignette("Estimating Effects")</code>.</p>
<p>At the heart of <code>MatchIt</code> are three classes of methods: distance matching, stratum matching, and pure subset selection. <em>Distance matching</em> involves considering a focal group (usually the treated group) and selecting members of the non-focal group (i.e., the control group) to pair with each member of the focal group based on the <em>distance</em> between units, which can be computed in one of several ways. Members of either group that are not paired are dropped from the sample. Nearest neighbor (<code>method = "nearest"</code>), optimal pair (<code>method = "optimal"</code>), optimal full (<code>method = "full"</code>), and genetic matching (<code>method = "genetic"</code>) are the methods of distance matching implemented in <code>MatchIt</code>. Typically, only the average treatment in the treated (ATT) or average treatment in the control (ATC), if the control group is the focal group, can be estimated after distance matching in <code>MatchIt</code> (full matching is an exception, described later).</p>
<p><em>Stratum matching</em> involves creating strata based on unique values of the covariates and assigning units with those covariate values into those strata. Any units that are in strata that lack either treated or control units are then dropped from the sample. Strata can be formed using the raw covariates (<code>method = "exact"</code>), coarsened versions of the covariates (<code>method = "cem"</code>), or coarsened versions of the propensity score (<code>method = "subclass"</code>). When no units are discarded, either the ATT, ATC, or average treatment effect in the population (ATE) can be estimated after stratum matching, though often some units are discarded, especially with exact and coarsened exact matching, making the estimand less clear. For use in estimating marginal treatment effects after exact matching, stratification weights are computed for the matched units first by computing a new “stratum propensity score” for each unit, which is the proportion of treated units in its stratum. The formulas for computing inverse probability weights from standard propensity scores are then applied to the new stratum propensity scores to form the new weights.</p>
<p>Pure subset selection involves selecting a subset of units form the original sample without considering the distance between individual units or strata that units might fall into. Subsets are selected to optimize a criterion subject to constraint on balance and remaining sample size. Cardinality and template matching (<code>method = "cardinality"</code>) are the methods of pure subset selection implemented in <code>MatchIt</code>. Both methods allow the user to specify the largest imbalance allowed in the resulting matched sample, and an optimization routine attempts to find the largest matched sample that satisfies those balance constraints. While cardinality matching does not target a specific estimand, template matching can be used to target the ATT, ATC, or ATE.</p>
<p>Below, we describe each of the matching methods implemented in <code>MatchIt</code>.</p>
</div>
<div class="section level2">
<h2 id="matching-methods">Matching Methods<a class="anchor" aria-label="anchor" href="#matching-methods"></a>
</h2>
<div class="section level3">
<h3 id="nearest-neighbor-matching-method-nearest">Nearest Neighbor Matching (<code>method = "nearest"</code>)<a class="anchor" aria-label="anchor" href="#nearest-neighbor-matching-method-nearest"></a>
</h3>
<p>Nearest neighbor matching is also known as greedy matching. It involves running through the list of treated units and selecting the closest eligible control unit to be paired with each treated unit. It is greedy in the sense that each pairing occurs without reference to how other units will be or have been paired, and therefore does not aim to optimize any criterion. Nearest neighbor matching is the most common form of matching used <span class="citation">(Thoemmes and Kim <a href="#ref-thoemmes2011" role="doc-biblioref">2011</a>; Zakrison, Austin, and McCredie <a href="#ref-zakrison2018" role="doc-biblioref">2018</a>)</span> and has been extensively studied through simulations. See <code><a href="../reference/method_nearest.html">?method_nearest</a></code> for the documentation for <code><a href="../reference/matchit.html">matchit()</a></code> with <code>method = "nearest"</code>.</p>
<p>Nearest neighbor matching requires the specification of a distance measure to define which control unit is closest to each treated unit. The default and most common distance is the <em>propensity score difference</em>, which is the difference between the propensity scores of each treated and control unit <span class="citation">(Stuart <a href="#ref-stuart2010" role="doc-biblioref">2010</a>)</span>. Another popular distance is the Mahalanobis distance, described in the section “Mahalanobis distance matching” below. The order in which the treated units are to be paired must also be specified and has the potential to change the quality of the matches <span class="citation">(Austin <a href="#ref-austin2013b" role="doc-biblioref">2013</a>; Rubin <a href="#ref-rubin1973" role="doc-biblioref">1973</a>)</span>; this is specified by the <code>m.order</code> argument. With propensity score matching, the default is to go in descending order from the highest propensity score; doing so allows the units that would have the hardest time finding close matches to be matched first <span class="citation">(Rubin <a href="#ref-rubin1973" role="doc-biblioref">1973</a>)</span>. Other orderings are possible, including random ordering, which can be tried multiple times until an adequate matched sample is found. When matching with replacement (i.e., where each control unit can be reused to be matched with any number of treated units), the matching order doesn’t matter.</p>
<p>When using a matching ratio greater than 1 (i.e., when more than 1 control units are requested to be matched to each treated unit), matching occurs in a cycle, where each treated unit is first paired with one control unit, and then each treated unit is paired with a second control unit, etc. Ties are broken deterministically based on the order of the units in the dataset to ensure that multiple runs of the same specification yield the same result (unless the matching order is requested to be random).</p>
</div>
<div class="section level3">
<h3 id="optimal-pair-matching-method-optimal">Optimal Pair Matching (<code>method = "optimal"</code>)<a class="anchor" aria-label="anchor" href="#optimal-pair-matching-method-optimal"></a>
</h3>
<p>Optimal pair matching (often just called optimal matching) is very similar to nearest neighbor matching in that it attempts to pair each treated unit with one or more control units. Unlike nearest neighbor matching, however, it is “optimal” rather than greedy; it is optimal in the sense that it attempts to choose matches that collectively optimize an overall criterion <span class="citation">(Hansen and Klopfer <a href="#ref-hansen2006" role="doc-biblioref">2006</a>; Gu and Rosenbaum <a href="#ref-gu1993" role="doc-biblioref">1993</a>)</span>. The criterion used is the sum of the absolute pair distances in the matched sample. See <code><a href="../reference/method_optimal.html">?method_optimal</a></code> for the documentation for <code><a href="../reference/matchit.html">matchit()</a></code> with <code>method = "optimal"</code>. Optimal pair matching in <code>MatchIt</code> depends on the <code>fullmatch()</code> function in the <code>optmatch</code> package <span class="citation">(Hansen and Klopfer <a href="#ref-hansen2006" role="doc-biblioref">2006</a>)</span>.</p>
<p>Like nearest neighbor matching, optimal pair matching requires the specification of a distance measure between units. Optimal pair matching can be thought of simply as an alternative to selecting the order of the matching for nearest neighbor matching. Optimal pair matching and nearest neighbor matching often yield the same or very similar matched samples; indeed, some research has indicated that optimal pair matching is not much better than nearest neighbor matching at yielding balanced matched samples <span class="citation">(Austin <a href="#ref-austin2013b" role="doc-biblioref">2013</a>)</span>.</p>
<p>The <code>tol</code> argument in <code>fullmatch()</code> can be supplied to <code><a href="../reference/matchit.html">matchit()</a></code> with <code>method = "optimal"</code>; this controls the numerical tolerance used to determine whether the optimal solution has been found. The default is fairly high and, for smaller problems, should be set much lower (e.g., by setting <code>tol = 1e-7</code>).</p>
</div>
<div class="section level3">
<h3 id="optimal-full-matching-method-full">Optimal Full Matching (<code>method = "full"</code>)<a class="anchor" aria-label="anchor" href="#optimal-full-matching-method-full"></a>
</h3>
<p>Optimal full matching (often just called full matching) assigns every treated and control unit in the sample to one subclass each <span class="citation">(Hansen <a href="#ref-hansen2004" role="doc-biblioref">2004</a>; Stuart and Green <a href="#ref-stuart2008a" role="doc-biblioref">2008</a>)</span>. Each subclass contains one treated unit and one or more control units or one control units and one or more treated units. It is optimal in the sense that the chosen number of subclasses and the assignment of units to subclasses minimize the sum of the absolute within-subclass distances in the matched sample. Weights are computed based on subclass membership, and these weights then function like propensity score weights and can be used to estimate a weighted treatment effect, ideally free of confounding by the measured covariates. See <code><a href="../reference/method_full.html">?method_full</a></code> for the documentation for <code><a href="../reference/matchit.html">matchit()</a></code> with <code>method = "full"</code>. Optimal full matching in <code>MatchIt</code> depends on the <code>fullmatch()</code> function in the <code>optmatch</code> package <span class="citation">(Hansen and Klopfer <a href="#ref-hansen2006" role="doc-biblioref">2006</a>)</span>.</p>
<p>Like the other distance matching methods, optimal full matching requires the specification of a distance measure between units. It can be seen a combination of distance matching and stratum matching: subclasses are formed with varying numbers of treated and control units, as with stratum matching, but the subclasses are formed based on minimizing within-pair distances and do not involve forming strata based on any specific variable, similar to distance matching. Unlike other distance matching methods, full matching can be used to estimate the ATE. Full matching can also be seen as a form of propensity score weighting that is less sensitive to the form of the propensity score model because the original propensity scores are used just to create the subclasses, not to form the weights directly <span class="citation">(Austin and Stuart <a href="#ref-austin2015a" role="doc-biblioref">2015</a><a href="#ref-austin2015a" role="doc-biblioref">b</a>)</span>. In addition, full matching does not have to rely on estimated propensity scores to form the subclasses and weights; other distance measures are allowed as well.</p>
<p>Although full matching uses all available units, there is a loss in precision due to the weights. Units may be weighted in such a way that they contribute less to the sample than would unweighted units, so the effective sample size (ESS) of the full matching weighted sample may be lower than even that of 1:1 pair matching. Balance is often far better after full matching than it is with 1:k matching, making full matching a good option to consider especially when 1:k matching is not effective or when the ATE is the target estimand.</p>
<p>The specification of the full matching optimization problem can be customized by supplying additional arguments that are passed to <code><a href="https://rdrr.io/pkg/optmatch/man/fullmatch.html" class="external-link">optmatch::fullmatch()</a></code>, such as <code>min.controls</code>, <code>max.controls</code>, <code>mean.controls</code>, and <code>omit.fraction</code>. As with optimal pair matching, the numerical tolerance value can be set much lower than the default with small problems by setting, e.g., <code>tol = 1e-7</code>.</p>
</div>
<div class="section level3">
<h3 id="genetic-matching-method-genetic">Genetic Matching (<code>method = "genetic"</code>)<a class="anchor" aria-label="anchor" href="#genetic-matching-method-genetic"></a>
</h3>
<p>Genetic matching is less a specific form of matching and more a way of specifying a distance measure for another form of matching. In practice, though, the form of matching used is nearest neighbor pair matching. Genetic matching uses a genetic algorithm, which is an optimization routine used for non-differentiable objective functions, to find scaling factors for each variable in a generalized Mahalanobis distance formula <span class="citation">(Diamond and Sekhon <a href="#ref-diamond2013" role="doc-biblioref">2013</a>)</span>. The criterion optimized by the algorithm is one based on covariate balance. Once the scaling factors have been found, nearest neighbor matching is performed on the scaled generalized Mahalanobis distance. See <code><a href="../reference/method_genetic.html">?method_genetic</a></code> for the documentation for <code><a href="../reference/matchit.html">matchit()</a></code> with <code>method = "genetic"</code>. Genetic matching in <code>MatchIt</code> depends on the <code>GenMatch()</code> function in the <code>Matching</code> package <span class="citation">(Sekhon <a href="#ref-sekhon2011" role="doc-biblioref">2011</a>)</span> to perform the genetic search and uses the <code>Matching</code> function to perform the nearest neighbor match using the scaled generalized Mahalanobis distance.</p>
<p>Genetic matching considers the generalized Mahalanobis distance between a treated unit <span class="math inline">\(i\)</span> and a control unit <span class="math inline">\(j\)</span> as <span class="math display">\[\delta_{GMD}(\mathbf{x}_i,\mathbf{x}_j, \mathbf{W})=\sqrt{(\mathbf{x}_i - \mathbf{x}_j)'(\mathbf{S}^{-1/2})'\mathbf{W}(\mathbf{S}^{-1/2})(\mathbf{x}_i - \mathbf{x}_j)}\]</span> where <span class="math inline">\(\mathbf{x}\)</span> is a <span class="math inline">\(p \times 1\)</span> vector containing the value of each of the <span class="math inline">\(p\)</span> included covariates for that unit, <span class="math inline">\(\mathbf{S}^{-1/2}\)</span> is the Cholesky decomposition of the covariance matrix <span class="math inline">\(\mathbf{S}\)</span> of the covariates, and <span class="math inline">\(\mathbf{W}\)</span> is a diagonal matrix with scaling factors <span class="math inline">\(w\)</span> on the diagonal: <span class="math display">\[
\mathbf{W}=\begin{bmatrix}
    w_1 &amp;  &amp; &amp; \\
     &amp; w_2 &amp; &amp; \\
     &amp;  &amp; \ddots &amp;\\
     &amp; &amp; &amp; w_p \\
    \end{bmatrix}
\]</span></p>
<p>When <span class="math inline">\(w_k=1\)</span> for all covariates <span class="math inline">\(k\)</span>, the computed distance is the standard Mahalanobis distance between units. Genetic matching estimates the optimal values of the <span class="math inline">\(w_k\)</span>s, where a user-specified criterion is used to define what is optimal. The default is to maximize the smallest p-value among balance tests for the covariates in the matched sample (both Kolmogorov-Smirnov tests and t-tests for each covariate).</p>
<p>In <code>MatchIt</code>, if a propensity score is specified, the default is to include the propensity score and the covariates in <span class="math inline">\(\mathbf{x}\)</span> and to optimize balance on the covariates. When <code>distance = "mahalanobis"</code> or the <code>mahvars</code> argument is specified, the propensity score is left out of <span class="math inline">\(\mathbf{x}\)</span>.</p>
<p>In all other respects, genetic matching functions just like nearest neighbor matching except that the matching itself is carried out by <code><a href="https://rdrr.io/pkg/Matching/man/Match.html" class="external-link">Matching::Match()</a></code> instead of by <code>MatchIt</code>. When using <code>method = "genetic"</code> in <code>MatchIt</code>, additional arguments passed to <code><a href="https://rdrr.io/pkg/Matching/man/GenMatch.html" class="external-link">Matching::GenMatch()</a></code> to control the genetic search process should be specified; in particular, the <code>pop.size</code> argument should be increased from its default of 100 to a much higher value. Doing so will make the algorithm take more time to finish but will generally improve the quality of the resulting matches. Different functions can be supplied to be used as the objective in the optimization using the <code>fit.func</code> argument.</p>
</div>
<div class="section level3">
<h3 id="exact-matching-method-exact">Exact Matching (<code>method = "exact"</code>)<a class="anchor" aria-label="anchor" href="#exact-matching-method-exact"></a>
</h3>
<p>Exact matching is a form of stratum matching that involves creating subclasses based on unique combinations of covariate values and assigning each unit into their corresponding subclass so that only units with identical covariate values are placed into the same subclass. Any units that are in subclasses lacking either treated or control units will be dropped. Exact matching is the most powerful matching method in that no functional form assumptions are required on either the treatment or outcome model for the method to remove confounding due to the measured covariates; the covariate distributions are exactly balanced. The problem with exact matching is that in general, few if any units will remain after matching, so the estimated effect will only generalize to a very limited population and can lack precision. Exact matching is particularly ineffective with continuous covariates, for which it might be that no two units have the same value, and with many covariates, for which it might be the case that no two units have the same combination of all covariates; this latter problem is known as the “curse of dimensionality”. See <code><a href="../reference/method_exact.html">?method_exact</a></code> for the documentation for <code><a href="../reference/matchit.html">matchit()</a></code> with <code>method = "exact"</code>.</p>
<p>It is possible to use exact matching on some covariates and another form of matching on the rest. This makes it possible to have exact balance on some covariates (typically categorical) and approximate balance on others, thereby gaining the benefits of both exact matching and the other matching method used. To do so, the other matching method should be specified in the <code>method</code> argument to <code><a href="../reference/matchit.html">matchit()</a></code> and the <code>exact</code> argument should be specified to contain the variables on which exact matching is to be done.</p>
</div>
<div class="section level3">
<h3 id="coarsened-exact-matching-method-cem">Coarsened Exact Matching (<code>method = "cem"</code>)<a class="anchor" aria-label="anchor" href="#coarsened-exact-matching-method-cem"></a>
</h3>
<p>Coarsened exact matching (CEM) is a form of stratum matching that involves first coarsening the covariates by creating bins and then performing exact matching on the new coarsened versions of the covariates <span class="citation">(Iacus, King, and Porro <a href="#ref-iacus2012" role="doc-biblioref">2012</a>)</span>. The degree and method of coarsening can be controlled by the user to manage the trade-off between exact and approximate balancing. For example, coarsening a covariate to two bins will mean that units that differ greatly on the covariate might be placed into the same subclass, while coarsening a variable to five bins may require units to be dropped due to not finding matches. Like exact matching, CEM is susceptible to the curse of dimensionality, making it a less viable solution with many covariates, especially with few units. Dropping units can also change the target population of the estimated effect. See <code><a href="../reference/method_cem.html">?method_cem</a></code> for the documentation for <code><a href="../reference/matchit.html">matchit()</a></code> with <code>method = "cem"</code>. CEM in <code>MatchIt</code> does not depend on any other package to perform the coarsening and matching, though it used to rely on the <code>cem</code> package.</p>
</div>
<div class="section level3">
<h3 id="subclassification-method-subclass">Subclassification (<code>method = "subclass"</code>)<a class="anchor" aria-label="anchor" href="#subclassification-method-subclass"></a>
</h3>
<p>Propensity score subclassification can be thought of as a form of coarsened exact matching with the propensity score as the sole covariate to be coarsened and matched on. The bins are usually based on specified quantiles of the propensity score distribution either in the treated group, control group, or overall, depending on the desired estimand. Propensity score subclassification is an old and well-studied method, though it can perform poorly compared to other, more modern propensity score methods such as full matching and weighting <span class="citation">(Austin <a href="#ref-austin2010" role="doc-biblioref">2010</a><a href="#ref-austin2010" role="doc-biblioref">a</a>)</span>. See <code><a href="../reference/method_subclass.html">?method_subclass</a></code> for the documentation for <code><a href="../reference/matchit.html">matchit()</a></code> with <code>method = "subclass"</code>.</p>
<p>The binning of the propensity scores is typically based on dividing the distribution of covariates into approximately equally sized bins. The user specifies the number of subclasses using the <code>subclass</code> argument and which group should be used to compute the boundaries of the bins using the <code>estimand</code> argument. Sometimes, subclasses can end up with no units from one of the treatment groups; by default, <code><a href="../reference/matchit.html">matchit()</a></code> moves a unit from an adjacent subclass into the lacking one to ensure that each subclass has at least one unit from each treatment group. The minimum number of units required in each subclass can be chosen by the <code>min.n</code> argument to <code><a href="../reference/matchit.html">matchit()</a></code>. If set to 0, an error will be thrown if any subclass lacks units from one of the treatment groups. Moving units from one subclass to another generally worsens the balance in the subclasses but can increase precision.</p>
<p>The default number of subclasses is 6, which is arbitrary and should not be taken as a recommended value. Although early theory has recommended the use of 5 subclasses, in general there is an optimal number of subclasses that is typically much larger than 5 but that varies among datasets <span class="citation">(Orihara and Hamada <a href="#ref-orihara2021" role="doc-biblioref">2021</a>)</span>. Rather than trying to figure this out for oneself, one can use optimal full matching (i.e., with <code>method = "full"</code>) to optimally create subclasses with one treated or one control unit that optimize a within-subclass distance criterion.</p>
<p>The output of propensity score subclassification includes the assigned subclasses and the subclassification weights. Effects can be estimated either within each subclass and then averaged across them, or a single marginal effect can be estimated using the subclassification weights. This latter method has been called marginal mean weighting through subclassification <span class="citation">(MMWS; Hong <a href="#ref-hong2010" role="doc-biblioref">2010</a>)</span> and fine stratification weighting <span class="citation">(Desai et al. <a href="#ref-desai2017" role="doc-biblioref">2017</a>)</span>. It is also implemented in the <code>WeightIt</code> package.</p>
</div>
<div class="section level3">
<h3 id="cardinality-and-template-matching-method-cardinality">Cardinality and Template Matching (<code>method = "cardinality"</code>)<a class="anchor" aria-label="anchor" href="#cardinality-and-template-matching-method-cardinality"></a>
</h3>
<p>Cardinality and template matching are pure subset selection methods that involve selecting a subset of the original sample without considering the distance between individual units or assigning units to pairs or subclasses. They can be thought of as a weighting method where the weights are restricted to be zero or one. Cardinality matching involves finding the largest sample that satisfies user-supplied balance constraints and constraints on the ratio of matched treated to matched control units <span class="citation">(Zubizarreta, Paredes, and Rosenbaum <a href="#ref-zubizarretaMatchingBalancePairing2014" role="doc-biblioref">2014</a>)</span>. It does not consider a specific estimand and can be a useful alternative to matching with a caliper for handling data with little overlap <span class="citation">(Visconti and Zubizarreta <a href="#ref-visconti2018" role="doc-biblioref">2018</a>)</span>. Template matching involves identifying a target distribution (e.g., the full sample for the ATE or the treated units for the ATT) and finding the largest subset of the treated and control groups that satisfy user-supplied balance constraints with respect to that target <span class="citation">(Bennett, Vielma, and Zubizarreta <a href="#ref-bennettBuildingRepresentativeMatched2020" role="doc-biblioref">2020</a>)</span>. See <code><a href="../reference/method_cardinality.html">?method_cardinality</a></code> for the documentation for using <code><a href="../reference/matchit.html">matchit()</a></code> with <code>method = "cardinality"</code>, including which inputs are required to request either cardinality matching or template matching.</p>
<p>Subset selection is performed by solving a mixed integer programming optimization problem with linear constraints. The problem involves maximizing the size of the matched sample subject to constraints on balance and sample size. For cardinality matching, the balance constraints refer to the mean difference for each covariate between the matched treated and control groups, and the sample size constraints require the matched treated and control groups to be the same size (or differ by a user-supplied factor). For template matching, the balance constraints refer to the mean difference for each covariate between each treatment group and the target distribution; for the ATE, this requires the mean of each covariate in each treatment group to be within a given tolerance of the mean of the covariate in the full sample, and for the ATT, this requires the mean of each covariate in the control group to be within a given tolerance of the mean of the covariate in the treated group, which is left intact. The balance tolerances are controlled by the <code>tols</code> and <code>std.tols</code> arguments.</p>
<p>The optimization problem requires a special solver to solve. Currently, the available options in <code>MatchIt</code> are the GLPK solver (through the <code>Rglpk</code> package), the SYMPHONY solver (through the <code>Rsymphony</code> package), and the Gurobi solver (through the <code>gurobi</code> package). The differences among the solvers are in performance; Gurobi is by far the best (fastest, least likely to fail to find a solution), but it is proprietary (though has a free trial and academic license) and is a bit more complicated to install. The <code>designmatch</code> package also provides an implementation of cardinality matching with more options than <code>MatchIt</code> offers.</p>
</div>
</div>
<div class="section level2">
<h2 id="customizing-the-matching-specification">Customizing the Matching Specification<a class="anchor" aria-label="anchor" href="#customizing-the-matching-specification"></a>
</h2>
<p>In addition to the specific matching method, other options are available for many of the matching methods to further customize the matching specification. These include different specifications of the distance measure, methods to perform alternate forms of matching in addition to the main method, prune units far from other units prior to matching, restrict possible matches, etc. Not all options are compatible with all matching methods.</p>
<div class="section level3">
<h3 id="specifying-the-propensity-score-or-other-distance-measure-distance">Specifying the propensity score or other distance measure (<code>distance</code>)<a class="anchor" aria-label="anchor" href="#specifying-the-propensity-score-or-other-distance-measure-distance"></a>
</h3>
<p>The distance measure is used to define how close two units are. In nearest neighbor matching, this is used to choose the nearest control unit to each treated unit. In optimal matching, this is used in the criterion that is optimized. By default, the distance measure is the propensity score difference, and the argument supplied to <code>distance</code> corresponds to the method of estimating the propensity score. In <code>MatchIt</code>, propensity scores are often labeled as “distance” values, even though the propensity score itself is not a distance measure. This is to reflect that the propensity score is used in creating the distance value, but other scores could be used, such as prognostic scores for prognostic score matching <span class="citation">(Hansen <a href="#ref-hansen2008a" role="doc-biblioref">2008</a>)</span>. The propensity score is more like a “position” value, in that it reflects the position of each unit in the matching space, and the difference between positions is the distance between them. If the the argument to <code>distance</code> is one of the allowed values (see <code><a href="../reference/distance.html">?distance</a></code> for these values) other than <code>"mahalanobis"</code> or is a numeric vector with one value per unit, the distance between units will be computed as the pairwise difference between propensity scores or the supplied values. Propensity scores are also used in propensity score subclassification and can optionally be used in genetic matching as a component of the generalized Mahalanobis distance. For exact, coarsened exact, and cardinality matching, the <code>distance</code> argument is ignored.</p>
<p>The default <code>distance</code> argument is <code>"glm"</code>, which estimates propensity scores using logistic regression or another generalized linear model. The <code>link</code> and <code>distance.options</code> arguments can be supplied to further specify the options for the propensity score models, including whether to use the raw propensity score or a linearized version of it (e.g., the logit of a logistic regression propensity score, which has been commonly referred to and recommended in the propensity score literature <span class="citation">(Austin <a href="#ref-austin2011a" role="doc-biblioref">2011</a>; Stuart <a href="#ref-stuart2010" role="doc-biblioref">2010</a>)</span>). Allowable options for the propensity score model include parametric and machine learning-based models, each of which have their strengths and limitations and may perform differently depending on the unique qualities of each dataset. We recommend multiple types of models be tried to find one that yields the best balance, as there is no way to make a single recommendation that will work for all cases.</p>
<p>The <code>distance</code> argument can also be specified as <code>"mahalanobis"</code>. For nearest neighbor and optimal (full or pair) matching, this triggers <code><a href="../reference/matchit.html">matchit()</a></code> not to estimate propensity scores but rather to use just the Mahalanobis distance, which is defined for a treated unit <span class="math inline">\(i\)</span> and a control unit <span class="math inline">\(j\)</span> as <span class="math display">\[\delta_{MD}(\mathbf{x}_i,\mathbf{x}_j)=\sqrt{(\mathbf{x}_i - \mathbf{x}_j)'S^{-1}(\mathbf{x}_i - \mathbf{x}_j)}\]</span></p>
<p>where <span class="math inline">\(\mathbf{x}\)</span> is a <span class="math inline">\(p \times 1\)</span> vector containing the value of each of the <span class="math inline">\(p\)</span> included covariates for that unit, <span class="math inline">\(S\)</span> is the covariance matrix among all the covariates, and <span class="math inline">\(S^{-1}\)</span> is the (generalized) inverse of <span class="math inline">\(S\)</span>. The R function <code><a href="https://rdrr.io/r/stats/mahalanobis.html" class="external-link">mahalanobis()</a></code> is used to compute this. Mahalanobis distance matching tends to work better with continuous covariates than with categorical covariates. For creating close pairs, Mahalanobis distance matching tends work better than propensity score matching because Mahalanobis distance-paired units will have close values on all of the covariates, whereas propensity score-paired units may be close on the propensity score but not on any of the covariates themselves. This feature was the basis of King and Nielsen’s <span class="citation">(<a href="#ref-king2019" role="doc-biblioref">2019</a>)</span> warning against using propensity scores for matching.</p>
<p><code>distance</code> can also be supplied as a matrix of distance values between units. This makes it possible to use handcrafted distance matrices or distances created outside <code>MatchIt</code>, e.g., using <code><a href="https://rdrr.io/pkg/optmatch/man/match_on-methods.html" class="external-link">optmatch::match_on()</a></code>. Only nearest neighbor, optimal pair, and optimal full matching allow this specification.</p>
<p>The propensity score can have uses other than as the basis for matching. It can be used to define a region of common support, outside which units are dropped prior to matching; this is implemented by the <code>discard</code> option. It can also be used to define a caliper, the maximum distance two units can be before they are prohibited from being paired with each other; this is implemented by the <code>caliper</code> argument. To estimate or supply a propensity score for one of these purposes but not use it as the distance measure for matching (e.g., to perform Mahalanobis distance matching instead), the <code>mahvars</code> argument can be specified. These options are described below.</p>
</div>
<div class="section level3">
<h3 id="implementing-common-support-restrictions-discard">Implementing common support restrictions (<code>discard</code>)<a class="anchor" aria-label="anchor" href="#implementing-common-support-restrictions-discard"></a>
</h3>
<p>The region of <em>common support</em> is the region of overlap between treatment groups. A common support restriction discards units that fall outside of the region of common support, preventing them from being matched to other units and included in the matched sample. This can reduce the potential for extrapolation and help the matching algorithms to avoid overly distant matches from occurring. In <code>MatchIt</code>, the <code>discard</code> option implements a common support restriction based on the propensity score. The argument can be supplied as <code>"treated"</code>, <code>"control"</code>, or <code>"both"</code>, which discards units in the corresponding group that fall outside the region of common support for the propensity score. The <code>reestimate</code> argument can be supplied to choose whether to re-estimate the propensity score in the remaining units. <strong>If units from the treated group are discarded based on a common support restriction, the estimand no longer corresponds to the ATT.</strong></p>
</div>
<div class="section level3">
<h3 id="caliper-matching-caliper">Caliper matching (<code>caliper</code>)<a class="anchor" aria-label="anchor" href="#caliper-matching-caliper"></a>
</h3>
<p>A <em>caliper</em> can be though of as a ring around each unit that limits to which other units that unit can be paired. Calipers are based on the propensity score or other covariates. Two units whose distance on a calipered covariate is larger than the caliper width for that covariate are not allowed to be matched to each other. Any units for which there are no available matches within the caliper are dropped from the matched sample. Calipers ensure paired units are close to each other on the calipered covariates, which can ensure good balance in the matched sample. Multiple variables can be supplied to <code>caliper</code> to enforce calipers on all of them simultaneously. Using calipers can be a good alternative to exact or coarsened exact matching to ensure only similar units are paired with each other. The <code>std.caliper</code> argument controls whether the provided calipers are in raw units or standard deviation units. <strong>If units from the treated group are left unmatched due to a caliper, the estimand no longer corresponds to the ATT.</strong></p>
</div>
<div class="section level3">
<h3 id="mahalanobis-distance-matching-mahvars">Mahalanobis distance matching (<code>mahvars</code>)<a class="anchor" aria-label="anchor" href="#mahalanobis-distance-matching-mahvars"></a>
</h3>
<p>To perform Mahalanobis distance matching without the need to estimate or use a propensity score, the <code>distance</code> argument can be set to <code>"mahalanobis"</code>. If a propensity score is to be estimated or used for a different purpose, such as in a common support restriction or a caliper, but you still want to perform Mahalanobis distance matching, variables should be supplied to the <code>mahvars</code> argument. The propensity scores will be generated using the <code>distance</code> specification, and matching will occur not on the covariates supplied to the main formula of <code><a href="../reference/matchit.html">matchit()</a></code> but rather on the covariates supplied to <code>mahvars</code>. To perform Mahalanobis distance matching within a propensity score caliper, for example, the <code>distance</code> argument should be set to the method of estimating the propensity score (e.g., <code>"glm"</code> for logistic regression), the <code>caliper</code> argument should be specified to the desired caliper width, and <code>mahvars</code> should be specified to perform Mahalanobis distance matching on the desired covariates within the caliper.</p>
</div>
<div class="section level3">
<h3 id="exact-matching-exact">Exact matching (<code>exact</code>)<a class="anchor" aria-label="anchor" href="#exact-matching-exact"></a>
</h3>
<p>To perform exact matching on all supplied covariates, the <code>method</code> argument can be set to <code>"exact"</code>. To perform exact matching only on some covariates and some other form of matching within exact matching strata on other covariates, the <code>exact</code> argument can be used. Covariates supplied to the <code>exact</code> argument will be matched exactly, and the form of matching specified by <code>method</code> (e.g., <code>"nearest"</code> for nearest neighbor matching) will take place within each exact matching stratum. This can be a good way to gain some of the benefits of exact matching without completely succumbing to the curse of dimensionality. As with exact matching performed with <code>method = "exact"</code>, any units in strata lacking members of one of the treatment groups will be left unmatched. Note that although matching occurs within each exact matching stratum, propensity score estimation and computation of the Mahalanobis distance occur in the full sample. <strong>If units from the treated group are unmatched due to an exact matching restriction, the estimand no longer corresponds to the ATT.</strong></p>
</div>
<div class="section level3">
<h3 id="anti-exact-matching-antiexact">Anti-exact matching (<code>antiexact</code>)<a class="anchor" aria-label="anchor" href="#anti-exact-matching-antiexact"></a>
</h3>
<p>Anti-exact matching adds a restriction such that a treated and control unit with same values of any of the specified anti-exact matching variables cannot be paired. This can be useful when finding comparison units outside of a unit’s group, such as when matching units in one group to units in another when units within the same group might otherwise be close matches. See examples <a href="https://stackoverflow.com/questions/66526115/propensity-score-matching-with-panel-data" class="external-link">here</a> and <a href="https://stackoverflow.com/questions/61120201/avoiding-duplicates-from-propensity-score-matching?rq=1" class="external-link">here</a>.</p>
</div>
<div class="section level3">
<h3 id="matching-with-replacement-replace">Matching with replacement (<code>replace</code>)<a class="anchor" aria-label="anchor" href="#matching-with-replacement-replace"></a>
</h3>
<p>Nearest neighbor matching and genetic matching have the option of matching with or without replacement, and this is controlled by the <code>replace</code> argument. Matching without replacement means that each control unit is matched to only one treated unit, while matching with replacement means that control units can be reused and matched to multiple treated units. Matching without replacement carries certain statistical benefits in that weights for each unit can be omitted or are more straightforward to include and dependence between units depends only on pair membership. Special standard error estimators are sometimes required for estimating effects after matching with replacement <span class="citation">(Austin and Cafri <a href="#ref-austin2020a" role="doc-biblioref">2020</a>)</span>, and methods for accounting for uncertainty are not well understood for non-continuous outcomes. Matching with replacement will tend to yield better balance though, because the problem of “running out” of close control units to match to treated units is avoided, though the reuse of control units will decrease the effect sample size, thereby worsening precision. (This problem occurs in the Lalonde dataset used in <code><a href="../articles/MatchIt.html">vignette("MatchIt")</a></code>, which is why nearest neighbor matching without replacement is not very effective there.) After matching with replacement, control units are assigned to more than one subclass, so the <code><a href="../reference/match.data.html">get_matches()</a></code> function should be used instead of <code><a href="../reference/match.data.html">match.data()</a></code> after matching with replacement if subclasses are to be used in follow-up analyses; see <code>vignette("Estimating Effects")</code> for details.</p>
<p>The <code>reuse.max</code> argument can also be used with <code>method = "nearest"</code> to control how many times each control unit can be reused as a match. Setting <code>reuse.max = 1</code> is equivalent to requiring matching without replacement (i.e., because each control can be used only once). Other values allow control units to be matched more than once, though only up to the specified number of times. Higher values will tend to improve balance at the cost of precision.</p>
</div>
<div class="section level3">
<h3 id="k1-matching-ratio">
<span class="math inline">\(k\)</span>:1 matching (<code>ratio</code>)<a class="anchor" aria-label="anchor" href="#k1-matching-ratio"></a>
</h3>
<p>The most common form of matching, 1:1 matching, involves pairing one control unit with each treated unit. To perform <span class="math inline">\(k\)</span>:1 matching (e.g., 2:1 or 3:1), which pairs (up to) <span class="math inline">\(k\)</span> control units with each treated unit, the <code>ratio</code> argument can be specified. Performing <span class="math inline">\(k\)</span>:1 matching can preserve precision by preventing too many control units from being unmatched and dropped from the matched sample, though the gain in precision by increasing <span class="math inline">\(k\)</span> diminishes rapidly after 4 <span class="citation">(Rosenbaum <a href="#ref-rosenbaum2020" role="doc-biblioref">2020</a>)</span>. Importantly, for <span class="math inline">\(k&gt;1\)</span>, the matches after the first match will generally be worse than the first match in terms of closeness to the treated unit, so increasing <span class="math inline">\(k\)</span> can also worsen balance. <span class="citation">Austin (<a href="#ref-austin2010a" role="doc-biblioref">2010</a><a href="#ref-austin2010a" role="doc-biblioref">b</a>)</span> found that 1:1 or 1:2 matching generally performed best in terms of mean squared error. In general, it makes sense to use higher values of <span class="math inline">\(k\)</span> while ensuring that balance is satisfactory. With nearest neighbor and optimal pair matching, variable <span class="math inline">\(k\)</span>:1 matching, in which the number of controls matched to each treated unit varies, can also be used; this can have improved performance over “fixed” <span class="math inline">\(k\)</span>:1 matching <span class="citation">(Ming and Rosenbaum <a href="#ref-ming2000" role="doc-biblioref">2000</a>)</span>. See <code><a href="../reference/method_nearest.html">?method_nearest</a></code> and <code><a href="../reference/method_optimal.html">?method_optimal</a></code> for information on implementing variable <span class="math inline">\(k\)</span>:1 matching.</p>
</div>
</div>
<div class="section level2">
<h2 id="choosing-a-matching-method">Choosing a Matching Method<a class="anchor" aria-label="anchor" href="#choosing-a-matching-method"></a>
</h2>
<p>Choosing the best matching method for one’s data depends on the unique characteristics of the dataset as well as the goals of the analysis. For example, because different matching methods can target different estimands, when certain estimands are desired, specific methods must be used. On the other hand, some methods may be more effective than others when retaining the target estimand is less important. Below we provide some guidance on choosing a matching method. Remember that multiple methods can (and should) be tried as long as the treatment effect is not estimated until a method has been settled on.</p>
<p>The criteria on which a matching specification should be judged are balance and remaining (effective) sample size after matching. Assessing balance is described in <code><a href="../articles/assessing-balance.html">vignette("assessing-balance")</a></code>. A typical workflow is similar to that demonstrated in <code><a href="../articles/MatchIt.html">vignette("MatchIt")</a></code>: try a matching method, and if it yields poor balance or an unacceptably low remaining sample size, try another, until a satisfactory specification has been found. It is important to assess balance broadly (i.e., beyond comparing the means of the covariates in the treated and control groups), and the search for a matching specification should not stop when a threshold is reached, but should attempt to come as close as possible to perfect balance <span class="citation">(Ho et al. <a href="#ref-ho2007" role="doc-biblioref">2007</a>)</span>. Even if the first matching specification appears successful at reducing imbalance, there may be another specification that could reduce it even further, thereby increasing the robustness of the inference and the plausibility of an unbiased effect estimate.</p>
<p>If the target of inference is the ATE, full matching, subclassification, and template matching can be used. If the target of inference is the ATT or ATC, any matching method may be used. When retaining the target estimand is not so important, additional options become available that involve discarding units in such a way that the original estimand is distorted. These include matching with a caliper, matching within a region of common support, cardinality matching, or exact or coarsened exact matching, perhaps on a subset of the covariates.</p>
<p>Because exact and coarsened exact matching aim to balance the entire joint distribution of covariates, they are the most powerful methods. If it is possible to perform exact matching, this method should be used. If continuous covariates are present, coarsened exact matching can be tried. Care should be taken with retaining the target population and ensuring enough matched units remain; unless the control pool is much larger than the treated pool, it is likely some (or many) treated units will be discarded, thereby changing the estimand and possibly dramatically reducing precision. These methods are typically only available in the most optimistic of circumstances, but they should be used first when those circumstances arise. It may also be useful to combine exact or coarsened exact matching on some covariates with another form of matching on the others (i.e., by using the <code>exact</code> argument).</p>
<p>When estimating the ATE, either subclassification, full matching, or template matching can be used. Full matching can be effective because it optimizes a balance criterion, often leading to better balance. With full matching, it’s also possible to exact match on some variables and match using the Mahalanobis distance, eliminating the need to estimate propensity scores. Template matching also ensures good balance, but because units are only given weights of zero one, a solution may not be feasible and many units may have to be discarded. For large datasets, neither full matching nor template matching may be possible, in which case subclassification is a faster solution. When using subclassification, the number of subclasses should be varied. With large samples, higher numbers of subclasses tend to yield better performance; one should not immediately settle for the default (6) or the often-cited recommendation of 5 without trying several other numbers.</p>
<p>When estimating the ATT, a variety of methods can be tried. Genetic matching can perform well at achieving good balance because it directly optimizes covariate balance. With larger datasets, it may take a long time to reach a good solution (though that solution will tend to be good as well). Template matching also will achieve good balance if a solution is feasible because balance is controlled by the user. Optimal pair matching and nearest neighbor matching without replacement tend to perform similarly to each other; nearest neighbor matching may be preferable for large datasets that cannot be handled by optimal matching. Nearest neighbor, optimal, and genetic matching allow some customizations like including covariates on which to exactly match, using the Mahalanobis distance instead of a propensity score difference, and performing <span class="math inline">\(k\)</span>:1 matching with <span class="math inline">\(k&gt;1\)</span>. Nearest neighbor matching with replacement, full matching, and subclassification all involve weighting the control units with nonuniform weights, which often allows for improved balancing capabilities but can be accompanied by a loss in effective sample size, even when all units are retained. There is no reason not to try many of these methods, varying parameters here and there, in search of good balance and high remaining sample size. As previously mentioned, no single method can be recommended above all others because the optimal specification depends on the unique qualities of each dataset.</p>
<p>When the target population is less important, for example, when engaging in treatment effect discovery or when when the sampled population is not of particular interest (e.g., it corresponds to an arbitrarily chosen hospital or school; see <span class="citation">Mao, Li, and Greene (<a href="#ref-mao2018" role="doc-biblioref">2018</a>)</span> for these and other reasons why retaining the target population may not be important), other methods that do not retain the characteristics of the original sample become available. These include matching with a caliper (on the propensity score or on the covariates themselves), cardinality matching, and more restrictive forms of matching like exact and coarsened exact matching, either on all covariates or just a subset, that are prone to discard units from the sample in such a way that the target population is changed. <span class="citation">Austin (<a href="#ref-austin2013b" role="doc-biblioref">2013</a>)</span> and Austin and Stuart <span class="citation">(<a href="#ref-austin2015c" role="doc-biblioref">2015</a><a href="#ref-austin2015c" role="doc-biblioref">a</a>, <a href="#ref-austin2015a" role="doc-biblioref">2015</a><a href="#ref-austin2015a" role="doc-biblioref">b</a>)</span> have found that caliper matching can be a particularly effective modification to nearest neighbor matching for eliminating imbalance and reducing bias when the target population is less relevant, but when inference to a specific target population is desired, using calipers can induce bias due to incomplete matching <span class="citation">(Rosenbaum and Rubin <a href="#ref-rosenbaum1985" role="doc-biblioref">1985</a><a href="#ref-rosenbaum1985" role="doc-biblioref">a</a>; Wang <a href="#ref-wang2020" role="doc-biblioref">2020</a>)</span>. Cardinality matching can be particularly effective in data with little overlap between the treatment groups <span class="citation">(Visconti and Zubizarreta <a href="#ref-visconti2018" role="doc-biblioref">2018</a>)</span> and can perform better than caliper matching <span class="citation">(de los Angeles Resa and Zubizarreta <a href="#ref-delosangelesresaDirectStableWeight2020" role="doc-biblioref">2020</a>)</span>.</p>
<p>It is important not to rely excessively on theoretical or simulation-based findings or specific recommendations when making choices about the best matching method to use. For example, although nearest neighbor matching without replacement balance covariates better than did subclassification with five or ten subclasses in Austin’s <span class="citation">(<a href="#ref-austin2009c" role="doc-biblioref">2009</a>)</span> simulation, this does not imply it will be superior in all datasets. Likewise, though <span class="citation">Rosenbaum and Rubin (<a href="#ref-rosenbaum1985a" role="doc-biblioref">1985</a><a href="#ref-rosenbaum1985a" role="doc-biblioref">b</a>)</span> and <span class="citation">Austin (<a href="#ref-austin2011a" role="doc-biblioref">2011</a>)</span> both recommend using a caliper of .2 standard deviations of the logit of the propensity score, this does not imply that caliper will be optimal in all scenarios, and other widths should be tried, though it should be noted that tightening the caliper on the propensity score can sometimes degrade performance <span class="citation">(King and Nielsen <a href="#ref-king2019" role="doc-biblioref">2019</a>)</span>.</p>
</div>
<div class="section level2">
<h2 id="reporting-the-matching-specification">Reporting the Matching Specification<a class="anchor" aria-label="anchor" href="#reporting-the-matching-specification"></a>
</h2>
<p>When reporting the results of a matching analysis, it is important to include the relevant details of the final matching specification and the process of arriving at it. Using <code><a href="https://rdrr.io/r/base/print.html" class="external-link">print()</a></code> on the <code>matchit</code> object synthesizes information on how the above arguments were used to provide a description of the matching specification. It is best to be as specific as possible to ensure the analysis is replicable and to allow audiences to assess its validity. Although citations recommending specific matching methods can be used to help justify a choice, the only sufficient justification is adequate balance and remaining sample size, regardless of published recommendations for specific methods. See <code><a href="../articles/assessing-balance.html">vignette("assessing-balance")</a></code> for instructions on how to assess and report the quality of a matching specification. After matching and estimating an effect, details of the effect estimation must be included as well; see <code><a href="../articles/estimating-effects.html">vignette("estimating-effects")</a></code> for instructions on how to perform and report on the analysis of a matched dataset.</p>
</div>
<div class="section level2 unnumbered">
<h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references">
<div id="ref-abadie2016">
<p>Abadie, Alberto, and Guido W. Imbens. 2016. “Matching on the Estimated Propensity Score.” <em>Econometrica</em> 84 (2): 781–807. <a href="https://doi.org/10.3982/ECTA11293" class="external-link">https://doi.org/10.3982/ECTA11293</a>.</p>
</div>
<div id="ref-abadie2006">
<p>———. 2006. “Large Sample Properties of Matching Estimators for Average Treatment Effects.” <em>Econometrica</em> 74 (1): 235–67. <a href="https://doi.org/10.1111/j.1468-0262.2006.00655.x" class="external-link">https://doi.org/10.1111/j.1468-0262.2006.00655.x</a>.</p>
</div>
<div id="ref-austin2011a">
<p>Austin, Peter C. 2011. “Optimal Caliper Widths for Propensity-Score Matching When Estimating Differences in Means and Differences in Proportions in Observational Studies.” <em>Pharmaceutical Statistics</em> 10 (2): 150–61. <a href="https://doi.org/10.1002/pst.433" class="external-link">https://doi.org/10.1002/pst.433</a>.</p>
</div>
<div id="ref-austin2009c">
<p>———. 2009. “The Relative Ability of Different Propensity Score Methods to Balance Measured Covariates Between Treated and Untreated Subjects in Observational Studies.” <em>Medical Decision Making</em> 29 (6): 661–77. <a href="https://doi.org/10.1177/0272989x09341755" class="external-link">https://doi.org/10.1177/0272989x09341755</a>.</p>
</div>
<div id="ref-austin2010">
<p>———. 2010a. “The Performance of Different Propensity-Score Methods for Estimating Differences in Proportions (Risk Differences or Absolute Risk Reductions) in Observational Studies.” <em>Statistics in Medicine</em> 29 (20): 2137–48. <a href="https://doi.org/10.1002/sim.3854" class="external-link">https://doi.org/10.1002/sim.3854</a>.</p>
</div>
<div id="ref-austin2010a">
<p>———. 2010b. “Statistical Criteria for Selecting the Optimal Number of Untreated Subjects Matched to Each Treated Subject When Using Many-to-One Matching on the Propensity Score.” <em>American Journal of Epidemiology</em> 172 (9): 1092–7. <a href="https://doi.org/10.1093/aje/kwq224" class="external-link">https://doi.org/10.1093/aje/kwq224</a>.</p>
</div>
<div id="ref-austin2013b">
<p>———. 2013. “A Comparison of 12 Algorithms for Matching on the Propensity Score.” <em>Statistics in Medicine</em> 33 (6): 1057–69. <a href="https://doi.org/10.1002/sim.6004" class="external-link">https://doi.org/10.1002/sim.6004</a>.</p>
</div>
<div id="ref-austin2020a">
<p>Austin, Peter C., and Guy Cafri. 2020. “Variance Estimation When Using Propensity-Score Matching with Replacement with Survival or Time-to-Event Outcomes.” <em>Statistics in Medicine</em> 39 (11): 1623–40. <a href="https://doi.org/10.1002/sim.8502" class="external-link">https://doi.org/10.1002/sim.8502</a>.</p>
</div>
<div id="ref-austin2014a">
<p>Austin, Peter C., and Dylan S. Small. 2014. “The Use of Bootstrapping When Using Propensity-Score Matching Without Replacement: A Simulation Study.” <em>Statistics in Medicine</em> 33 (24): 4306–19. <a href="https://doi.org/10.1002/sim.6276" class="external-link">https://doi.org/10.1002/sim.6276</a>.</p>
</div>
<div id="ref-austin2015c">
<p>Austin, Peter C., and Elizabeth A. Stuart. 2015a. “Estimating the Effect of Treatment on Binary Outcomes Using Full Matching on the Propensity Score.” <em>Statistical Methods in Medical Research</em> 26 (6): 2505–25. <a href="https://doi.org/10.1177/0962280215601134" class="external-link">https://doi.org/10.1177/0962280215601134</a>.</p>
</div>
<div id="ref-austin2015a">
<p>———. 2015b. “The Performance of Inverse Probability of Treatment Weighting and Full Matching on the Propensity Score in the Presence of Model Misspecification When Estimating the Effect of Treatment on Survival Outcomes.” <em>Statistical Methods in Medical Research</em> 26 (4): 1654–70. <a href="https://doi.org/10.1177/0962280215584401" class="external-link">https://doi.org/10.1177/0962280215584401</a>.</p>
</div>
<div id="ref-bennettBuildingRepresentativeMatched2020">
<p>Bennett, Magdalena, Juan Pablo Vielma, and José R. Zubizarreta. 2020. “Building Representative Matched Samples with Multi-Valued Treatments in Large Observational Studies.” <em>Journal of Computational and Graphical Statistics</em>, May, 1–29. <a href="https://doi.org/10.1080/10618600.2020.1753532" class="external-link">https://doi.org/10.1080/10618600.2020.1753532</a>.</p>
</div>
<div id="ref-delosangelesresaDirectStableWeight2020">
<p>de los Angeles Resa, María, and José R. Zubizarreta. 2020. “Direct and Stable Weight Adjustment in Non-Experimental Studies with Multivalued Treatments: Analysis of the Effect of an Earthquake on Post-Traumatic Stress.” <em>Journal of the Royal Statistical Society: Series A (Statistics in Society)</em> n/a (n/a). <a href="https://doi.org/10.1111/rssa.12561" class="external-link">https://doi.org/10.1111/rssa.12561</a>.</p>
</div>
<div id="ref-desai2017">
<p>Desai, Rishi J., Kenneth J. Rothman, Brian T. Bateman, Sonia Hernandez-Diaz, and Krista F. Huybrechts. 2017. “A Propensity-Score-Based Fine Stratification Approach for Confounding Adjustment When Exposure Is Infrequent:” <em>Epidemiology</em> 28 (2): 249–57. <a href="https://doi.org/10.1097/EDE.0000000000000595" class="external-link">https://doi.org/10.1097/EDE.0000000000000595</a>.</p>
</div>
<div id="ref-diamond2013">
<p>Diamond, Alexis, and Jasjeet S. Sekhon. 2013. “Genetic Matching for Estimating Causal Effects: A General Multivariate Matching Method for Achieving Balance in Observational Studies.” <em>Review of Economics and Statistics</em> 95 (3): 932945. <a href="https://doi.org/10.1162/REST_a_00318" class="external-link">https://doi.org/10.1162/REST_a_00318</a>.</p>
</div>
<div id="ref-gu1993">
<p>Gu, Xing Sam, and Paul R. Rosenbaum. 1993. “Comparison of Multivariate Matching Methods: Structures, Distances, and Algorithms.” <em>Journal of Computational and Graphical Statistics</em> 2 (4): 405. <a href="https://doi.org/10.2307/1390693" class="external-link">https://doi.org/10.2307/1390693</a>.</p>
</div>
<div id="ref-hansen2004">
<p>Hansen, Ben B. 2004. “Full Matching in an Observational Study of Coaching for the Sat.” <em>Journal of the American Statistical Association</em> 99 (467): 609–18. <a href="https://doi.org/10.1198/016214504000000647" class="external-link">https://doi.org/10.1198/016214504000000647</a>.</p>
</div>
<div id="ref-hansen2008a">
<p>———. 2008. “The Prognostic Analogue of the Propensity Score.” <em>Biometrika</em> 95 (2): 481–88. <a href="https://doi.org/10.1093/biomet/asn004" class="external-link">https://doi.org/10.1093/biomet/asn004</a>.</p>
</div>
<div id="ref-hansen2006">
<p>Hansen, Ben B., and Stephanie O. Klopfer. 2006. “Optimal Full Matching and Related Designs via Network Flows.” <em>Journal of Computational and Graphical Statistics</em> 15 (3): 609–27. <a href="https://doi.org/10.1198/106186006X137047" class="external-link">https://doi.org/10.1198/106186006X137047</a>.</p>
</div>
<div id="ref-ho2007">
<p>Ho, Daniel E., Kosuke Imai, Gary King, and Elizabeth A. Stuart. 2007. “Matching as Nonparametric Preprocessing for Reducing Model Dependence in Parametric Causal Inference.” <em>Political Analysis</em> 15 (3): 199–236. <a href="https://doi.org/10.1093/pan/mpl013" class="external-link">https://doi.org/10.1093/pan/mpl013</a>.</p>
</div>
<div id="ref-hong2010">
<p>Hong, Guanglei. 2010. “Marginal Mean Weighting Through Stratification: Adjustment for Selection Bias in Multilevel Data.” <em>Journal of Educational and Behavioral Statistics</em> 35 (5): 499–531. <a href="https://doi.org/10.3102/1076998609359785" class="external-link">https://doi.org/10.3102/1076998609359785</a>.</p>
</div>
<div id="ref-iacus2012">
<p>Iacus, Stefano M., Gary King, and Giuseppe Porro. 2012. “Causal Inference Without Balance Checking: Coarsened Exact Matching.” <em>Political Analysis</em> 20 (1): 1–24. <a href="https://doi.org/10.1093/pan/mpr013" class="external-link">https://doi.org/10.1093/pan/mpr013</a>.</p>
</div>
<div id="ref-king2019">
<p>King, Gary, and Richard Nielsen. 2019. “Why Propensity Scores Should Not Be Used for Matching.” <em>Political Analysis</em>, May, 1–20. <a href="https://doi.org/10.1017/pan.2019.11" class="external-link">https://doi.org/10.1017/pan.2019.11</a>.</p>
</div>
<div id="ref-mao2018">
<p>Mao, Huzhang, Liang Li, and Tom Greene. 2018. “Propensity Score Weighting Analysis and Treatment Effect Discovery.” <em>Statistical Methods in Medical Research</em>, June, 096228021878117. <a href="https://doi.org/10.1177/0962280218781171" class="external-link">https://doi.org/10.1177/0962280218781171</a>.</p>
</div>
<div id="ref-ming2000">
<p>Ming, Kewei, and Paul R. Rosenbaum. 2000. “Substantial Gains in Bias Reduction from Matching with a Variable Number of Controls.” <em>Biometrics</em> 56 (1): 118–24. <a href="https://doi.org/10.1111/j.0006-341X.2000.00118.x" class="external-link">https://doi.org/10.1111/j.0006-341X.2000.00118.x</a>.</p>
</div>
<div id="ref-orihara2021">
<p>Orihara, Shunichiro, and Etsuo Hamada. 2021. “Determination of the Optimal Number of Strata for Propensity Score Subclassification.” <em>Statistics &amp; Probability Letters</em> 168 (January): 108951. <a href="https://doi.org/10.1016/j.spl.2020.108951" class="external-link">https://doi.org/10.1016/j.spl.2020.108951</a>.</p>
</div>
<div id="ref-rosenbaum2020">
<p>Rosenbaum, Paul R. 2020. “Modern Algorithms for Matching in Observational Studies.” <em>Annual Review of Statistics and Its Application</em> 7 (1): 143–76. <a href="https://doi.org/10.1146/annurev-statistics-031219-041058" class="external-link">https://doi.org/10.1146/annurev-statistics-031219-041058</a>.</p>
</div>
<div id="ref-rosenbaum1985">
<p>Rosenbaum, Paul R., and Donald B. Rubin. 1985a. “The Bias Due to Incomplete Matching.” <em>Biometrics</em> 41 (1): 103–16. <a href="https://doi.org/10.2307/2530647" class="external-link">https://doi.org/10.2307/2530647</a>.</p>
</div>
<div id="ref-rosenbaum1985a">
<p>———. 1985b. “Constructing a Control Group Using Multivariate Matched Sampling Methods That Incorporate the Propensity Score.” <em>The American Statistician</em> 39 (1): 33. <a href="https://doi.org/10.2307/2683903" class="external-link">https://doi.org/10.2307/2683903</a>.</p>
</div>
<div id="ref-rubin1973">
<p>Rubin, Donald B. 1973. “Matching to Remove Bias in Observational Studies.” <em>Biometrics</em> 29 (1): 159. <a href="https://doi.org/10.2307/2529684" class="external-link">https://doi.org/10.2307/2529684</a>.</p>
</div>
<div id="ref-schafer2008">
<p>Schafer, Joseph L., and Joseph Kang. 2008. “Average Causal Effects from Nonrandomized Studies: A Practical Guide and Simulated Example.” <em>Psychological Methods</em> 13 (4): 279–313. <a href="https://doi.org/10.1037/a0014268" class="external-link">https://doi.org/10.1037/a0014268</a>.</p>
</div>
<div id="ref-sekhon2011">
<p>Sekhon, Jasjeet S. 2011. “Multivariate and Propensity Score Matching Software with Automated Balance Optimization: The Matching Package for R.” <em>Journal of Statistical Software</em> 42 (1): 1–52. <a href="https://doi.org/10.18637/jss.v042.i07" class="external-link">https://doi.org/10.18637/jss.v042.i07</a>.</p>
</div>
<div id="ref-stuart2008">
<p>Stuart, Elizabeth A. 2008. “Developing Practical Recommendations for the Use of Propensity Scores: Discussion of ‘A Critical Appraisal of Propensity Score Matching in the Medical Literature Between 1996 and 2003’ by Peter Austin,Statistics in Medicine.” <em>Statistics in Medicine</em> 27 (12): 2062–5. <a href="https://doi.org/10.1002/sim.3207" class="external-link">https://doi.org/10.1002/sim.3207</a>.</p>
</div>
<div id="ref-stuart2010">
<p>———. 2010. “Matching Methods for Causal Inference: A Review and a Look Forward.” <em>Statistical Science</em> 25 (1): 1–21. <a href="https://doi.org/10.1214/09-STS313" class="external-link">https://doi.org/10.1214/09-STS313</a>.</p>
</div>
<div id="ref-stuart2008a">
<p>Stuart, Elizabeth A., and Kerry M. Green. 2008. “Using Full Matching to Estimate Causal Effects in Nonexperimental Studies: Examining the Relationship Between Adolescent Marijuana Use and Adult Outcomes.” <em>Developmental Psychology</em> 44 (2): 395–406. <a href="https://doi.org/10.1037/0012-1649.44.2.395" class="external-link">https://doi.org/10.1037/0012-1649.44.2.395</a>.</p>
</div>
<div id="ref-thoemmes2011">
<p>Thoemmes, Felix J., and Eun Sook Kim. 2011. “A Systematic Review of Propensity Score Methods in the Social Sciences.” <em>Multivariate Behavioral Research</em> 46 (1): 90–118. <a href="https://doi.org/10.1080/00273171.2011.540475" class="external-link">https://doi.org/10.1080/00273171.2011.540475</a>.</p>
</div>
<div id="ref-visconti2018">
<p>Visconti, Giancarlo, and José R. Zubizarreta. 2018. “Handling Limited Overlap in Observational Studies with Cardinality Matching.” <em>Observational Studies</em> 4 (1): 217–49. <a href="https://doi.org/10.1353/obs.2018.0012" class="external-link">https://doi.org/10.1353/obs.2018.0012</a>.</p>
</div>
<div id="ref-wan2019">
<p>Wan, Fei. 2019. “Matched or Unmatched Analyses with Propensity-Scorematched Data?” <em>Statistics in Medicine</em> 38 (2): 289–300. <a href="https://doi.org/10.1002/sim.7976" class="external-link">https://doi.org/10.1002/sim.7976</a>.</p>
</div>
<div id="ref-wang2020">
<p>Wang, Jixian. 2020. “To Use or Not to Use Propensity Score Matching?” <em>Pharmaceutical Statistics</em>, August. <a href="https://doi.org/10.1002/pst.2051" class="external-link">https://doi.org/10.1002/pst.2051</a>.</p>
</div>
<div id="ref-zakrison2018">
<p>Zakrison, T. L., Peter C. Austin, and V. A. McCredie. 2018. “A Systematic Review of Propensity Score Methods in the Acute Care Surgery Literature: Avoiding the Pitfalls and Proposing a Set of Reporting Guidelines.” <em>European Journal of Trauma and Emergency Surgery</em> 44 (3): 385–95. <a href="https://doi.org/10.1007/s00068-017-0786-6" class="external-link">https://doi.org/10.1007/s00068-017-0786-6</a>.</p>
</div>
<div id="ref-zubizarreta2014">
<p>Zubizarreta, José R., Ricardo D. Paredes, and Paul R. Rosenbaum. 2014. “Matching for Balance, Pairing for Heterogeneity in an Observational Study of the Effectiveness of for-Profit and Not-for-Profit High Schools in Chile.” <em>The Annals of Applied Statistics</em> 8 (1): 204–31. <a href="https://doi.org/10.1214/13-AOAS713" class="external-link">https://doi.org/10.1214/13-AOAS713</a>.</p>
</div>
<div id="ref-zubizarretaMatchingBalancePairing2014">
<p>Zubizarreta, José R., Ricardo D. Paredes, and Paul R. Rosenbaum. 2014. “Matching for Balance, Pairing for Heterogeneity in an Observational Study of the Effectiveness of for-Profit and Not-for-Profit High Schools in Chile.” <em>The Annals of Applied Statistics</em> 8 (1): 204–31. <a href="https://doi.org/10.1214/13-AOAS713" class="external-link">https://doi.org/10.1214/13-AOAS713</a>.</p>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by Daniel Ho, Kosuke Imai, Gary King, Elizabeth Stuart, Noah Greifer.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.2.</p>
</div>

      </footer>
</div>

  


  

  </body>
</html>
